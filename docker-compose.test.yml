version: '3.7'

services:
  backend:
    build: .
    command: uvicorn app.main:app --host 0.0.0.0 --port 8050
    volumes:
      - ./src/:/app/
    ports:
      - "8050:8050"
    environment:
      - POSTGRES_URL=postgresql+asyncpg://dummy_login:dummy_pwd@test_db/dummy_db
      - OLLAMA_ENDPOINT=http://ollama:11434
      - OLLAMA_MODEL=tinydolphin:1.1b-v2.8-q4_0
      - SUPERADMIN_GH_PAT=${SUPERADMIN_GH_PAT}
      - SUPERADMIN_LOGIN=superadmin_login
      - SUPERADMIN_PWD=superadmin_pwd
      - GH_OAUTH_ID=${GH_OAUTH_ID}
      - GH_OAUTH_SECRET=${GH_OAUTH_SECRET}
      - DEBUG=true
    depends_on:
      test_db:
        condition: service_healthy
      ollama:
        condition: service_healthy

  test_db:
    image: postgres:15-alpine
    expose:
      - 5432
    environment:
      - POSTGRES_USER=dummy_login
      - POSTGRES_PASSWORD=dummy_pwd
      - POSTGRES_DB=dummy_db
    healthcheck:
      test: ["CMD-SHELL", "sh -c 'pg_isready -U dummy_login -d dummy_db'"]
      interval: 10s
      timeout: 3s
      retries: 3

  ollama:
    image: ollama/ollama:0.1.25
    command: serve
    volumes:
      - "$HOME/.ollama:/root/.ollama"
    expose:
      - 11434
    healthcheck:
      test: ["CMD-SHELL", "ollama pull 'tinydolphin:1.1b-v2.8-q4_0'"]
      interval: 5s
      timeout: 1m
      retries: 3
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

volumes:
  ollama:
